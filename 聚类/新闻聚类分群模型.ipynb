{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity=\"all\" # cell 的多行输出"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "新闻种类繁复多样，可以分为财经、体育、科技、娱乐等题材。在本案例中，笔者根据10个关键词从百度新闻爬取了962条新闻（具体方法可以参考本章最后的第2个“补充知识点”），且每个关键词对应的新闻条数相近，现在需要通过Python编程对每条新闻划分类别，匹配到正确的版面，这实际上就是在对新闻进行聚类分群。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>关键词</th>\n",
       "      <th>标题</th>\n",
       "      <th>网址</th>\n",
       "      <th>来源</th>\n",
       "      <th>时间</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>信托公司2019年上半年经营业绩概览</td>\n",
       "      <td>http://www.financialnews.com.cn/jrsb_m/xt/zx/2...</td>\n",
       "      <td>中国金融新闻网</td>\n",
       "      <td>2019年07月23日 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>首单信托型企业ABS获批</td>\n",
       "      <td>http://www.jjckb.cn/2018-10/23/c_137552198.htm</td>\n",
       "      <td>经济参考网</td>\n",
       "      <td>2018年10月23日 12:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>华能贵诚信托孙磊:金融科技助力打造开放信托生态</td>\n",
       "      <td>https://baijiahao.baidu.com/s?id=1639276579449...</td>\n",
       "      <td>同花顺财经</td>\n",
       "      <td>2019年07月17日 10:49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施</td>\n",
       "      <td>https://finance.qq.com/a/20190716/007898.htm</td>\n",
       "      <td>腾讯财经</td>\n",
       "      <td>2019年07月16日 18:53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>华能信托</td>\n",
       "      <td>格力电器股权转让意向方闭门开会 华能信托赫然在列</td>\n",
       "      <td>https://finance.sina.com.cn/trust/roll/2019-05...</td>\n",
       "      <td>新浪</td>\n",
       "      <td>2019年05月22日 22:53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    关键词                            标题  \\\n",
       "0  华能信托            信托公司2019年上半年经营业绩概览   \n",
       "1  华能信托                  首单信托型企业ABS获批   \n",
       "2  华能信托       华能贵诚信托孙磊:金融科技助力打造开放信托生态   \n",
       "3  华能信托  华能贵诚信托孙磊:金融科技已经成为信托行业重要的基础设施   \n",
       "4  华能信托      格力电器股权转让意向方闭门开会 华能信托赫然在列   \n",
       "\n",
       "                                                  网址       来源  \\\n",
       "0  http://www.financialnews.com.cn/jrsb_m/xt/zx/2...  中国金融新闻网   \n",
       "1     http://www.jjckb.cn/2018-10/23/c_137552198.htm    经济参考网   \n",
       "2  https://baijiahao.baidu.com/s?id=1639276579449...    同花顺财经   \n",
       "3       https://finance.qq.com/a/20190716/007898.htm     腾讯财经   \n",
       "4  https://finance.sina.com.cn/trust/roll/2019-05...       新浪   \n",
       "\n",
       "                  时间  \n",
       "0  2019年07月23日 00:00  \n",
       "1  2018年10月23日 12:21  \n",
       "2  2019年07月17日 10:49  \n",
       "3  2019年07月16日 18:53  \n",
       "4  2019年05月22日 22:53  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_excel(\"./data/新闻.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新闻文本处理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "文本数据，如本节中的新闻标题文本。这种文本类型的数据需要转换为数值类型的数据才能在Python中处理。\n",
    "\n",
    "这项工作需要用到两个核心技术\n",
    "- 中文分词\n",
    "- 文本向量化。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 中文分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\26598\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.502 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我\n",
      "爱\n",
      "北京\n",
      "天安门\n"
     ]
    }
   ],
   "source": [
    "# jieba分词示例\n",
    "import jieba\n",
    "word=jieba.cut('我爱北京天安门')\n",
    "for i in word:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信托公司 2019 年 上半年 经营 业绩 概览\n"
     ]
    }
   ],
   "source": [
    "# 处理第一个标题\n",
    "word=jieba.cut(df.iloc[0]['标题'])\n",
    "result=' '.join(word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['信托公司 2019 年 上半年 经营 业绩 概览',\n",
       " '首单 信托 型 企业 ABS 获批',\n",
       " '华能 贵 诚信 托孙磊 : 金融 科技 助力 打造 开放 信托 生态',\n",
       " '华能 贵 诚信 托孙磊 : 金融 科技 已经 成为 信托 行业 重要 的 基础设施',\n",
       " '格力电器 股权 转让 意向 方 闭门 开会   华能 信托 赫然 在 列']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 处理所有标题\n",
    "words=[]\n",
    "# iterrows()函数用于遍历 DataFrame 的每一行\n",
    "for i,row in df.iterrows():\n",
    "    words.append(' '.join(jieba.cut(row['标题'])))\n",
    "words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立词频矩阵"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1, 1],\n",
       "       [1, 1, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer 文本向量化函数\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "test=['金融 科技 厉害', '华能 信托 厉害']\n",
    "vect=CountVectorizer()\n",
    "X=vect.fit_transform(test)\n",
    "X=X.toarray()\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "CountVectorizer()函数会先根据空格来识别每一句话中的词语\n",
    "\n",
    "例如，它能从第1条新闻标题中识别出“金融”“科技”“厉害”这3个词，从第2条新闻标题中识别出“华能”“信托”“厉害”这3个词，这2条标题一共能识别出“金融”“科技”“华能”“信托”“厉害”这5个不同的词。\n",
    "\n",
    "这5个词便构成了这2条新闻标题的词袋，CountVectorizer()函数会自动对词袋中的词进行编号，通过vocabulary_属性便能获取词袋的内容及相应编号"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'金融': 4, '科技': 3, '厉害': 2, '华能': 1, '信托': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CountVectorizer()函数最开始是设计用来做英文单词向量化的，所以此处词袋中的词并不是按照拼音首字母进行排序的\n",
    "vect.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标题1为“金融科技厉害”，特征3、4、5对应的词在标题1中各出现1次，上表中在特征3、4、5处对应的值就是1，特征1、2对应的词在标题1中出现0次，对应的值就是0，所以标题1对应的数值数组就是[00111]。\n",
    "\n",
    "同理，标题2对应的数值数组是[11100]，这样便完成了文本数据的数值化。如果一个词出现了不止一次，例如，在某个标题中“金融”这个词出现了2次，那么其对应的值就是2。\n",
    "\n",
    "此外，CountVectorizer()函数会自动过滤掉一个字的词，这样会过滤掉“的”“之”等没有重要含义的词，不过同时也会过滤掉“爱”“坑”等可能有重要含义的词，因此，这个特点既是一个优势，也是一个劣势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00700</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>08s</th>\n",
       "      <th>09</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>150</th>\n",
       "      <th>...</th>\n",
       "      <th>黄萍</th>\n",
       "      <th>黄金</th>\n",
       "      <th>黑客</th>\n",
       "      <th>黑灰产</th>\n",
       "      <th>黑金</th>\n",
       "      <th>黑马</th>\n",
       "      <th>鼓手</th>\n",
       "      <th>鼻祖</th>\n",
       "      <th>齐聚</th>\n",
       "      <th>龙风</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 3402 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00700  03  04  08s  09  10  100  11  12  150  ...  黄萍  黄金  黑客  黑灰产  黑金  黑马  \\\n",
       "0      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "1      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "2      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "3      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "4      0   0   0    0   0   0    0   0   0    0  ...   0   0   0    0   0   0   \n",
       "\n",
       "   鼓手  鼻祖  齐聚  龙风  \n",
       "0   0   0   0   0  \n",
       "1   0   0   0   0  \n",
       "2   0   0   0   0  \n",
       "3   0   0   0   0  \n",
       "4   0   0   0   0  \n",
       "\n",
       "[5 rows x 3402 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构造特征变量\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "vect=CountVectorizer()\n",
    "X=vect.fit_transform(words)\n",
    "X=X.toarray()\n",
    "# 从此袋中获取不带编号的词\n",
    "word_bag2=vect.get_feature_names()\n",
    "df=pd.DataFrame(X,columns=word_bag2)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(962, 3402)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 3, 3, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kms=KMeans(n_clusters=10,random_state=123)\n",
    "k_data=kms.fit_predict(df)\n",
    "k_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['... 电视 总台 七夕 特别节目 《 天下 有情人 》 浪漫 升级 , 引领 传统 文化 新 ...',\n",
       "       '北京 文化 “ 封神 ” : 爆款 如何 持续',\n",
       "       '深挖 “ 仓颉造 字 ” 历史 文化 , 寿光 这个 村新 时代 文明 实践 有 高招',\n",
       "       '让 夜间 经济 更 有 文化 味   哪里 才 是 真正 “ 网红 打卡 地 ” ?',\n",
       "       '嘉兴 : “ 伯鸿 城市 书房 ” 构筑 风雅 桐乡 最美 文化 地标',\n",
       "       '“ 中华文化 边疆 行 — — 走进 昭通 ” 大型 系列 文化 活动 拉开帷幕',\n",
       "       '文化 增 活力   旅游 添 魅力   文旅 融合 讓濟南 旅游 悄然 發生 著 變化',\n",
       "       '华北 、 华东 文化 消费 热情 高   文化 场馆 周边 配套 不足 最 被 诟病',\n",
       "       '「 地 评线 」 “ 可爱 中国 ” 凝聚 文化 自信', '党建 · 文化 · 环境   锦江区 水井坊 打造 国际化 社区',\n",
       "       '何 建华 专栏 : 钱汉东 为什么 钟情 追求 “ 最 文化 ”',\n",
       "       '文化 _   全球 电竞 大会 在 沪 举行 , 启动 首届 “ 上海 电 竞周 ” , 举办 近 百场 ...',\n",
       "       '昔日 垃圾 地   今朝 文化园 — — 月亮 湾 社区 综合 文化 服务中心 成为 居民 “ ...',\n",
       "       '讲好 中国 故事   展示 文化 魅力', '【 文化 履游 】 这个 地方 , 文化 与 美食 都 不能 错过',\n",
       "       '太原 能否 当选 2020 年 “ 东亚 文化 之 都 ” 8 月底 揭晓',\n",
       "       '2019 首届 明德 儒商 论坛 聚焦 中国 智慧 , 提升 文化 自信',\n",
       "       '人民日报 海外版 : 抓住 “ 真 文化 ” 而 不是 “ 假 标签 ”', '青春 芒果 节 引领 青年 文化',\n",
       "       '中国 陶都 ( 宜兴 ) 陶瓷 文化 推介会 在 北京 举行', '文聚邦 — — 文化 产业链 的 生态 服务商',\n",
       "       '弘扬 传统 婚姻 文化 , 上演 古代 汉服 婚礼 秀 , 执子之手 与尔 偕老', '淮河 文化 主题公园 风景 美如画',\n",
       "       '书 博会 : 以书为 媒 , 打造 全民 阅读 的 文化 盛宴',\n",
       "       '文化 趣味 席卷 ChinaJoy   盛趣 游戏 新文化 C 位出 道',\n",
       "       '从 风景 到 红色 文化 , 贵州省 一应俱全 , 期待 大家 前来 游历',\n",
       "       '智库 | 美国 的 文化 心理 及 对 中美关系 的 影响', '廣東 “ 夜游 ” 首開   博物 館 更添 文化 味',\n",
       "       '沧州 大运河 文化 带 建设 全面 提速', '在 供给 侧 改革 推动 下   公共 文化 服务 改变 了 什么',\n",
       "       '铁西区 : 用 工业 文化 点亮 “ 盛京 十二 时辰 ”', '曹洁 : 城市更新 是 文化 、 空间 和 人 的 融合',\n",
       "       '从 读书 品位 的 变化   看 深圳 的 文化 选择', '真实性 复原 背后 的 文化 选择',\n",
       "       '感受 多彩 运河 文化 这场 重磅 展览 超 25 万人次 观展', '文化 为魂 , 桐乡 打造 城市 发展 核心 竞争力',\n",
       "       '这个 巴依 宅院 藏有 新疆 “ 清明上河图 ” , 现已 成为 伊宁 文化 地标 !',\n",
       "       '任县 创新 民调 工作 模式 — — 党建 引领 保 稳定   “ 和 合 文化 ” 润 民心',\n",
       "       '视频 | 临清 首届 汉服 文化 旅游 周 开幕   千年 魅力 文化 尽 在 山水 间',\n",
       "       '第十届 中国 宜兴 国际 陶瓷 文化 艺术节 将 于 10 月 举行',\n",
       "       '廣東 “ 夜游 ” 首開   博物 館 更添 文化 味', '沧州 大运河 文化 带 建设 全面 提速',\n",
       "       '城市 繁荣   文化 奠基', '图集 / / 咱 身边 的 文化 活动 之 文化馆',\n",
       "       '... 光线 传媒 就 能 改命 ? 你 可能 忘 了 曾经 押 中 《 战狼 2 》 的 北京 文化 了',\n",
       "       '掌趣 科技 黄萍 : 加速 游戏 文化 融合 发展',\n",
       "       '吉林 · 四平 满族 文化 旅游节 - 宝泰 广场 满族 民俗文化 旅游 购物 周',\n",
       "       '一部 岭南 祠堂 文化 极 简史 , 道 出 多少 广东 人 的 百年 骄傲',\n",
       "       '何 建华 专栏 : 钱汉东 为什么 钟情 追求 “ 最 文化 ”',\n",
       "       '丝路 新语 · 中外 文化 小 使者 巡礼 活动 在 京 启动', '一代 盛世 , 文化 繁荣 的 背后 , 揭秘 唐朝',\n",
       "       '「 财经 纵横 」 戴斌 : 旅游 研究 与 文化 建设 , 初心 在 哪里 ...',\n",
       "       '淳安 有个 小山村 , 被誉为 最有 文化 的 村庄',\n",
       "       '故宫博物院 翁连溪 : 沉睡 的 历史 文化 艺术 在 现代 家居设计 中 的 华丽 复活',\n",
       "       'TGC 腾讯 数字 文创 : 腾讯 的 文化 抱负', '【 方志 动态 】 《 南皮 文化 》 创刊',\n",
       "       '青海 天峻 : 打造 文旅 品牌 展现 草原 文化 魅力',\n",
       "       '视频 | 临清 首届 汉服 文化 旅游 周 开幕   千年 魅力 文化 尽 在 山水 间',\n",
       "       '太原 能否 当选 2020 年 “ 东亚 文化 之 都 ” , 8 月底 揭晓 !',\n",
       "       '廣東 “ 夜游 ” 首開   博物 館 更添 文化 味', '沧州 大运河 文化 带 建设 全面 提速',\n",
       "       '城市 繁荣   文化 奠基', '在 供给 侧 改革 推动 下   公共 文化 服务 改变 了 什么',\n",
       "       '曹洁 : 城市更新 是 文化 、 空间 和 人 的 融合', '真实性 复原 背后 的 文化 选择',\n",
       "       '滋 文化 溢 芬芳   幸福 味长', '欧洲 有 骑士 文化 , 日本 有 武士 文化 , 中国 的 你 知道 吗 ?',\n",
       "       '继往开来   “ 史上 最丑 哪吒 ” 彰显 文化 自信 的 魅力',\n",
       "       '《 长安 十二 时辰 》 最火 的 “ 非遗 文化 ” 是 啥 ? 网友 投票 : 第一名 是 它',\n",
       "       '加快 & quot ; 文化圈 & quot ; 建设   山东 威海 打通 文化 服务 & quot ; 最后 一 公里 & quot ;',\n",
       "       '弘扬 中华 传统 文化 , 传播 百年 民族 品牌', '文化 消费 成为 扩大内需 新 引擎',\n",
       "       '文化 趣味 席卷 ChinaJoy   盛趣 游戏 新文化 C 位出 道',\n",
       "       '文脉 同 国脉 相连 ( 新 中国 发展 面对面 ④ ) — — 中国 何以 文化 自信 ?',\n",
       "       '文化 消费 成为 扩大内需 新 引擎', '文化 主题 展馆 哪家 策划 好   建筑 结构   博涛 文化 硬件 研制',\n",
       "       '永鸿 集团 : 掘金 文化 地产', '讲好 中国 故事   展示 文化 魅力',\n",
       "       '全国 书画艺术 名家 赴 涉县 石井 沟送 文化 下乡', '腾讯 的 “ 文化 苦旅 ”',\n",
       "       '他 在 儒家 传统 文化 中 长大', '“ 吃 文化 ” 之 甘肃 平凉 特色',\n",
       "       '... ’ 同心 助力 乡村 振兴 ” 主题 党日 活动 奏响 文化 助力 新 农村 建设 主旋律',\n",
       "       '阿里巴巴 平台 则 成为 连接 中华 传统 文化 和 年轻人 的 一道 鹊桥',\n",
       "       'TGC 腾讯 数字 文创 : 腾讯 的 文化 抱负',\n",
       "       '将 文化 与 价值观 写入 产品   腾讯 “ 新文创 ” 助推 数字 文化 拥抱 产业 互联网',\n",
       "       '腾讯 马晓轶 : 推动 数字 文化 高质量 发展   共同 打造 中国 文化 符号'], dtype='<U70')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "word_ary=np.array(words)\n",
    "word_ary[k_data==1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出 上述基本都与文化相关，分类效果还是可以"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "# eps参数（画圆半径）为1，min_samples参数（圆内最小样本数）为3\n",
    "dbs=DBSCAN(eps=1,min_samples=3)\n",
    "d_data=dbs.fit_predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,  0,  1,  2,  3,\n",
       "        4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,  2,\n",
       "        3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,\n",
       "        2,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,  8,  0,\n",
       "        1,  2,  3,  4,  5,  6,  7,  8, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1,  9, 10, 11,  9, 10, 11,  9, 10, 11,\n",
       "        9, 10, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 12, 13,\n",
       "       14, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 12, 13, 14,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, 12, 13, 14, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1,\n",
       "       -1, -1, -1, -1, -1, -1, -1, -1, -1, -1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从图中可以看出，DBSCAN算法对新闻标题的聚类效果较差，其中有大量离群点（-1），即不知道这条新闻标题属于什么分类。\n",
    "\n",
    "因为进行文本向量化后，每个新闻标题都有3401个特征，过多的特征容易导致样本点间的距离较远，从而产生离群点\n",
    "\n",
    "因此对于新闻文本而言，KMeans算法的聚类效果很好，DBSCAN算法的聚类效果则不尽如人意，这也说明了对于特征变量较多的数据，KMeans算法的聚类效果要优于DBSCAN算法的聚类效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型优化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "误差主要原因是新闻标题长短不一，在进行中文分词及文本向量化后，长标题和短标题的距离就较远"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>信托</th>\n",
       "      <th>华能</th>\n",
       "      <th>很好</th>\n",
       "      <th>想去</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   信托  华能  很好  想去\n",
       "0   1   1   0   1\n",
       "1   1   1   1   1\n",
       "2   2   2   2   2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_test = ['想去 华能 信托', '华能 信托 很好 想去', '华能 信托 很好 想去 华能 信托 很好 想去']\n",
    "# 文本向量化\n",
    "vect=CountVectorizer()\n",
    "X_test=vect.fit_transform(words_test)\n",
    "X_test=X_test.toarray()\n",
    "\n",
    "word_bag2=vect.get_feature_names()\n",
    "df_test=pd.DataFrame(X_test,columns=word_bag2)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算欧式距离\n",
    "np.linalg.norm(df_test.iloc[0]-df_test.iloc[1])\n",
    "np.linalg.norm(df_test.iloc[1]-df_test.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.       , 0.8660254, 0.8660254],\n",
       "       [0.8660254, 1.       , 1.       ],\n",
       "       [0.8660254, 1.       , 1.       ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 余弦相似度\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第i行第j列的数字表示第i个数据和第j个数据的余弦相似度。\n",
    "\n",
    "例如，第2行第3列的数字1是第2条新闻标题和第3条新闻标题的余弦相似度\n",
    "\n",
    "而第2行第1列的数字0.866则是第2条新闻标题和第1条新闻标题的余弦相似度\n",
    "\n",
    "左上角至右下角的对角线上的数字都为1，这些数字的意义不大，因为它们表示数据与本身的余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Miniconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 用余弦相似性 代替 欧氏距离 对模型进行优化\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity=cosine_similarity(df)\n",
    "from sklearn.cluster import KMeans\n",
    "kms=KMeans(n_clusters=10,random_state=123)\n",
    "k_data=kms.fit_predict(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
